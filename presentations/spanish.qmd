
---
title: "Usa las APIs de IA que Chrome tiene para ti"
author: "Sebastian Gomez - @sebasgojs"
format:
  revealjs:
    theme: black
    css: styles.css
    highlight-style: monokai
    slide-number: true
    slide-level: 2
    hash: true
    logo: assets/logo.png
    footer: "www.sebastian-gomez.com - @sebasgojs"
    include-after-body:
      - text: |
          <script src="scripts.js"></script>
---
<script type="module">
    import { pipeline } from 'https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.8.0';
</script>
<div style="text-align: center; margin-top: 20px;">
  <img src="assets/slide Promo.png" style="max-width: 600px; width: 100%; border-radius: 15px; border: 4px solid white; box-shadow: 0 4px 10px rgba(0,0,0,0.3);">
  <p style="font-size: 1.2em; margin-top: 10px; margin-bottom: 5px;">Engineering Manager at Twilio</p>
  <p style="font-size: 1.2em; margin-top: 0;">GDE en Web Technologies</p>
</div>

::: {.notes}
¬øAlguna vez has estado en un avi√≥n sin internet? ¬øQuisieras seguir chateando con Gemini, ChatGPT o Claude Code?, quiz√° no, pero quiz√° hayas creado un espectacular sitio web que necesite traducci√≥n (y no pagar por ella), o quiz√° desees que un texto en tu aplicaci√≥n se vea diferente dependiendo del pa√≠s, el lenguaje o regi√≥n? Unet√© a m√≠ en esta charla donde te muestro c√≥mo usar IA en aplicaciones para el browser, sin costo y totalmente offline. Solo necesito tus superpoderes con javascript y el resto corre por mi cuenta.
:::

## Comenzando

Habilita estas flags en `chrome://flags`:

- Prompt API for Gemini Nano
- Summarization API for Gemini Nano
- Writer/Rewriter API for Gemini Nano

. . .

Luego actualiza **Optimization Guide On Device Model** en `chrome://components`.

::: {.notes}
Estas flags son experimentales y necesarias para habilitar las APIs de Gemini Nano. El componente "Optimization Guide" es el que descarga y gestiona el modelo en s√≠. Aseg√∫rense de que est√© actualizado ("Fully downloaded") antes de intentar usar las APIs.
:::


## Cambiando el Paradigma {background-gradient="linear-gradient(to bottom right, #2c3e50, #4ca1af)"}

::: {style="display: flex; justify-content: space-around; align-items: center; margin-top: 40px;"}

::: {style="opacity: 0.7; background: rgba(0,0,0,0.3); padding: 20px; border-radius: 10px;"}
<h3>IA Tradicional</h3>
Usuario &rarr; Servidor &rarr; Respuesta
:::

::: {style="font-size: 2em;"}
&rarr;
:::

::: {style="background: rgba(255,255,255,0.1); padding: 20px; border-radius: 10px; border: 2px solid #4ca1af;"}
<h3>Web AI</h3>
Usuario &larr; **Navegador** &rarr; Modelo
:::

:::

::: {style="margin-top: 40px;"}
Descentralizaci√≥n de la Inteligencia Artificial.
:::

::: {.notes}
Estamos moviendo la inteligencia de la nube al borde (edge). En lugar de enviar datos a un servidor centralizado, traemos el modelo al usuario. Esto cambia fundamentalmente la arquitectura de las aplicaciones web modernas.
:::


## ¬øPor qu√© ejecutar IA en el navegador? {background-image="assets/privacy_shield_background_1764037863751.png" background-opacity="0.4"}

<ul style="background: rgba(0,0,0,0.6); padding: 40px; border-radius: 15px;">
  <li class="fragment"><strong>Privacidad:</strong> Procesamiento local de datos sensibles (ej. encriptaci√≥n E2EE).</li>
  <li class="fragment"><strong>Latencia:</strong> Resultados m√°s r√°pidos (sin viajes al servidor).</li>
  <li class="fragment"><strong>Offline:</strong> Funciona sin conexi√≥n a internet.</li>
  <li class="fragment"><strong>Costo:</strong> Menores costos de API para desarrolladores.</li>
  <li class="fragment"><strong>H√≠brido:</strong> Modelos locales para usuarios gratuitos, nube para premium.</li>
</ul>

::: {.notes}
La privacidad es el gran ganador aqu√≠: datos sensibles como salud o finanzas nunca salen del dispositivo. La latencia es cero porque no hay round-trip al servidor. Y el costo de inferencia se mueve del proveedor al consumidor (su bater√≠a/GPU), lo que escala infinitamente gratis para ustedes.
:::


## Las Limitaciones

- **Hardware:** Depende de la GPU/RAM del usuario.
- **Tama√±o de Descarga:** Modelos enormes (GBs).
- **Bater√≠a:** Consumo energ√©tico alto.

::: {.notes}
No todo es color de rosa. Los modelos son grandes (Gemma 2B son ~1.4GB). La descarga inicial es pesada. Y correr estos modelos consume bater√≠a r√°pidamente. Hay que ser responsables y cargar los modelos solo cuando sea necesario.
:::


## El Espectro de Web AI

::: {style="display:flex; gap:20px;"}

::: {style="flex:1; border:1px solid #555; padding:20px; border-radius: 10px; background: rgba(255,255,255,0.05);"}
<h3>BYOM</h3>
Bring Your Own Model

<small>T√∫ env√≠as el modelo (MediaPipe)</small>
:::

::: {style="flex:1; border:1px solid #fff; padding:20px; border-radius: 10px; background: rgba(255,255,255,0.1);"}
<h3>Built-in AI</h3>
Gemini Nano

<small>El navegador incluye el modelo</small>
:::

:::

::: {.notes}
Tenemos dos sabores principales:
1. **BYOM (Bring Your Own Model):** Usan WebGPU (v√≠a MediaPipe o Transformers.js) para correr cualquier modelo (Gemma, Llama, Phi). Control total, pero ustedes gestionan la descarga del modelo.
2. **Built-in AI:** El navegador ya tiene Gemini Nano integrado. Cero descarga para su web, API estandarizada, pero limitados al modelo que Chrome provee.
:::


# {background-image="assets/browser_brain_background_1764037882897.png" background-opacity="0.5"}

<ul style="background: rgba(0,0,0,0.6); padding: 30px; border-radius: 15px; text-shadow: 1px 1px 2px #000; list-style-type: none;">
  <li><strong>Modelo:</strong> Gemini Nano</li>
  <li><strong>Distribuci√≥n:</strong> Gestionado por Chrome</li>
  <li><strong>Acceso:</strong> APIs de JavaScript simples</li>
</ul>

::: {.notes}
Gemini Nano es el modelo que impulsa todo esto. Chrome lo gestiona, as√≠ que no tienen que preocuparse por la distribuci√≥n.
:::

## La API de Prompt

La "Navaja Suiza" de la IA Integrada.

- Conversaci√≥n libre
- Sesiones con estado
- Genial para chatbots y consultas generales

::: {.notes}
Es la API m√°s vers√°til. Pueden usarla para casi cualquier tarea de texto a texto.
:::

## Paso 1: Verificar Disponibilidad

```javascript
// 1. Verificar disponibilidad
const availability = await LanguageModel.availability();
if (availability === 'unavailable') return;
if (availability === 'downloadable') {
  console.log("Modelo se descargar√° al usarlo");
}
console.log("Modelo disponible");
```

<div style="margin-top: 20px;">
  <button id="btn-availability" onclick="runAvailabilityDemo()" class="demo-btn">Verificar Disponibilidad</button>
  <div id="output-availability" style="margin-top: 10px; text-align: left; background: #333; padding: 10px; border-radius: 5px; min-height: 40px; font-family: monospace; white-space: pre-wrap;"></div>
</div>

::: {.notes}
Siempre verifiquen disponibilidad. El usuario podr√≠a no tener el modelo descargado a√∫n.
:::

## Paso 2: Crear Sesi√≥n

```javascript
// 2. Crear sesi√≥n (con monitor de descarga)
const session = await LanguageModel.create({
  expectedInputs: [{ type: 'text', languages: ['es'] }],
  expectedOutputs: [{ type: 'text', languages: ['es'] }],
  systemPrompt: "Eres un asistente √∫til.",
  monitor(m) {
    m.addEventListener('downloadprogress', (e) => {
      console.log(`Descargado ${e.loaded * 100}%`);
    });
  }
});
```

<div style="margin-top: 20px;">
  <button id="btn-session" onclick="runSessionDemo()" class="demo-btn">Crear Sesi√≥n</button>
  <div id="output-session" style="margin-top: 10px; text-align: left; background: #333; padding: 10px; border-radius: 5px; min-height: 40px; font-family: monospace; white-space: pre-wrap;"></div>
</div>

::: {.notes}
La sesi√≥n mantiene el contexto de la conversaci√≥n. Tambi√©n pueden monitorear el progreso de descarga aqu√≠.
:::

## Paso 3: Generaci√≥n (Streaming)

```javascript
// 3. Streaming
const stream = session.promptStreaming("Explicame algo!");
for await (const chunk of stream) {
  console.log(chunk);
}
```

<div style="margin-top: 20px;">
  <button id="btn-streaming" onclick="runStreamingDemo()" class="demo-btn">Generar Respuesta</button>
  <div id="output-streaming" style="margin-top: 10px; text-align: left; background: #333; padding: 10px; border-radius: 5px; min-height: 60px; max-height: 200px; overflow-y: auto; font-family: monospace; white-space: pre-wrap;"></div>
</div>

::: {.notes}
Streaming es vital para la percepci√≥n de velocidad. No hagan esperar al usuario por toda la respuesta.
:::

## Demo: Prompt Playground

<iframe src="../prompt-api-playground/index.html" width="100%" height="600px" style="border: 1px solid #555; background: white;" data-preload></iframe>

## Contando Tokens

```javascript
// La API que retorna el n√∫mero de tokens ha cambiado entre 
// Chrome Stable y Canary y el m√©todo se renombr√≥ de 
// `countPromptTokens(input)` a `measureInputUsage(input)`.
// El c√≥digo abajo asegura que ambos casos se manejen.
if (session.countPromptTokens) {
  cost = await session.countPromptTokens(value);
} else if (session.measureInputUsage) {
  cost = await session.measureInputUsage(value);
}
console.log(`Tokens: ${count}`);
```

<div style="margin-top: 20px;">
  <textarea id="token-input" placeholder="Escribe algo aqu√≠ para contar tokens..." style="width: 80%; height: 100px; font-size: 18px; padding: 10px; background: #333; color: white; border: 1px solid #555;"></textarea>
  <div id="token-count" style="margin-top: 10px; font-size: 24px; font-weight: bold;">Tokens: 0</div>
</div>

::: {.notes}
Contar tokens es importante para gestionar el contexto y evitar l√≠mites.
:::

## API de Resumen

Optimizada para condensar texto.

- Resumir transcripciones de reuniones.
- Resumir chats de soporte para CRM.
- Resumir rese√±as de productos.
- Resumir art√≠culos largos (TL;DR).
- Generar t√≠tulos de art√≠culos.
- Resumir preguntas de Q&A.

::: {.notes}
Esta API es espec√≠fica para resumir. Es m√°s eficiente que usar la API de Prompt para esta tarea.
:::

## Paso 1: Disponibilidad

<div>window.Sumarizer</div>



```javascript
const availability = await Summarizer.availability();
if (availability === 'unavailable') return;
console.log("Modelo disponible");
```

<div style="margin-top: 20px;">
  <button id="btn-sum-avail" onclick="runSummarizerAvailability()" class="demo-btn">Verificar</button>
  <div id="output-sum-avail" style="margin-top: 10px; text-align: left; background: #333; padding: 10px; border-radius: 5px; min-height: 40px; font-family: monospace; white-space: pre-wrap;">Esperando...</div>
</div>

::: {.notes}
El patr√≥n es el mismo: verificar disponibilidad primero.
:::



## Paso 2: Crear Summarizer

```javascript
const summarizer = await Summarizer.create({
  format: 'plain-text',
  monitor(m) {
    m.addEventListener('downloadprogress', (e) => {
      console.log(`Descargado ${e.loaded * 100}%`);
    });
  }
});
```

<div style="margin-top: 20px;">
  <button id="btn-sum-create" onclick="runSummarizerCreation()" class="demo-btn">Crear Summarizer</button>
  <div id="output-sum-create" style="margin-top: 10px; text-align: left; background: #333; padding: 10px; border-radius: 5px; min-height: 40px; font-family: monospace; white-space: pre-wrap;">Esperando...</div>
</div>

::: {.notes}
Configuren el formato de salida y monitoreen la descarga si es necesario.
:::

## Paso 3: Resumir

```javascript
const text = document.getElementById('input-sum').value;
const summary = await summarizer.summarize(text);
console.log(summary);
```

<div style="margin-top: 20px;">
  <textarea id="input-sum" class="demo-input" style="height: 100px;" placeholder="Pega un texto largo aqu√≠ para resumir...">Web AI es una nueva tecnolog√≠a que permite ejecutar modelos de inteligencia artificial directamente en el navegador web. Esto ofrece beneficios significativos incluyendo privacidad, ya que los datos no salen del dispositivo, y latencia reducida puesto que no se requieren viajes al servidor. Tambi√©n habilita funcionalidad offline. Sin embargo, requiere descargar modelos grandes y puede ser intensivo en hardware.</textarea>
  <button id="btn-sum-exec" onclick="runSummarizerExecution()" class="demo-btn">Resumir Texto</button>
  <div id="output-sum-exec" style="margin-top: 10px; text-align: left; background: #333; padding: 10px; border-radius: 5px; min-height: 60px; font-family: monospace; white-space: pre-wrap; font-size: 20px;"></div>
</div>

::: {.notes}
Simplemente pasen el texto y obtengan el resumen.
:::

## Ejemplo: Configuraci√≥n Avanzada

```javascript
const options = { type: "teaser", expectedInputLanguages: ["ja"] };

const availability = await Summarizer.availability(options);

if (availability !== "unavailable") {
  // We're good! Let's do the summarization using the built-in API.
  if (availability !== "available") {
    console.log("Sit tight, we need to do some downloading...");
  }

  const summarizer = await Summarizer.create(options);
  console.log(await summarizer.summarize("La vida es bella"));
} else {
  // Either the API overall, or  the combination of teaser 
  // + Japanese input, is not available. Use the cloud.
  console.log(await doCloudSummarization("La vida es bella"));
}
```

## Output
<div style="margin-top: 20px;">
  <button id="btn-sum-adv" onclick="runAdvancedSummarizerDemo()" class="demo-btn">Ejecutar Demo</button>
  <div id="output-sum-adv" style="margin-top: 10px; text-align: left; background: #333; padding: 10px; border-radius: 5px; min-height: 40px; font-family: monospace; white-space: pre-wrap;"></div>
</div>


## Demo: Summarization Playground

<iframe src="../summarization-api-playground/index.html" width="100%" height="600px" style="border: 1px solid #555; background: white;" data-preload></iframe>

### Paso 1: Disponibilidad (Detector) {class="bg-lang-detect"}

::: {.split-layout .code-heavy .vertical}

::: {.split-col .code-col}
```javascript
// Modern API: LanguageDetector
const availability = await LanguageDetector.availability();

if (availability === 'unavailable') {
  console.log("Modelo no disponible");
  return;
}

console.log("Modelo disponible");
```
:::

::: {.split-col .demo-col}

<p style="font-size: 0.8em; opacity: 0.8; margin-bottom: 15px;">Verifica si tu navegador soporta la detecci√≥n de idioma.</p>

<button id="btn-lang-avail" class="demo-btn" onclick="runLangDetectAvailability()">
  <span class="icon">‚ö°</span> Verificar Disponibilidad
</button>

<div id="output-lang-avail" class="demo-output">Esperando verificaci√≥n...</div>
:::

::: {.notes}
Antes de traducir o procesar, a menudo necesitamos saber el idioma.
:::

:::

## Paso 2: Crear Detector {class="bg-lang-detect"}

::: {.split-layout .code-heavy .vertical}

::: {.split-col .code-col}
```javascript
// Modern API: LanguageDetector
const detector = await LanguageDetector.create({
  monitor(m) {
    m.addEventListener('downloadprogress', (e) => {
      console.log(`Descargado ${e.loaded * 100}%`);
    });
  }
});
```
:::

::: {.split-col .demo-col}
<button id="btn-lang-create" class="demo-btn" onclick="runLangDetectCreation()">
  <span class="icon">‚öôÔ∏è</span> Crear Detector
</button>

<div class="progress-container">
  <div id="progress-lang-create" class="progress-bar"></div>
</div>

<div id="output-lang-create" class="demo-output">Esperando...</div>
:::

::: {.notes}
Este modelo es mucho m√°s peque√±o y r√°pido de descargar que Gemini Nano.
:::

:::

## Paso 3: Detectar Idioma {class="bg-lang-detect playground-slide"}

::: {.split-layout .code-heavy .vertical}

::: {.split-col .code-col}
```javascript
const results = await detector.detect(inputText);
console.log(results);
```
:::

::: {.split-col .demo-col}
<input type="text" id="input-lang-exec" class="demo-input" value="Bonjour le monde" placeholder="Escribe algo...">
<button id="btn-lang-exec" class="demo-btn" onclick="runLangDetectExecution()">
  <span class="icon">üîç</span> Detectar
</button>
<div id="output-lang-exec" class="demo-output">El resultado aparecer√° aqu√≠...</div>
:::

::: {.notes}
Devuelve una lista de idiomas probables con sus niveles de confianza.
:::

:::

## Demo: Translation Playground

<iframe src="../translation-language-detection-api-playground/index.html" width="100%" height="600px" style="border: 1px solid #555; background: white;" data-preload></iframe>

## Casos de Uso: Writer

- Explicar datos estructurados (gr√°ficos, tablas).
- Expandir listas de pros/contras.
- Generar biograf√≠as desde CVs.
- Superar el bloqueo del escritor (borradores).
- Crear posts para redes sociales.

## Paso 1: Disponibilidad (Writer) {class="bg-writer"}

::: {.split-layout .code-heavy .vertical}

::: {.split-col .code-col}
```javascript
// Modern API: Writer
const availability = await Writer.availability();

if (availability === 'unavailable') {
  console.log("Modelo no disponible");
  return;
}

console.log("Modelo disponible:", availability);
```
:::

::: {.split-col .demo-col}
<button id="btn-writer-avail" class="demo-btn" onclick="runWriterAvailability()">
  <span class="icon">‚ö°</span> Verificar Disponibilidad
</button>
<div id="output-writer-avail" class="demo-output">Esperando...</div>
:::

::: {.notes}
Ayuda a escribir, refinar y elaborar textos.
:::

:::

## Paso 2: Crear Writer {class="bg-writer"}

::: {.split-layout .code-heavy .vertical}

::: {.split-col .code-col}
```javascript
// Modern API: Writer
const writer = await Writer.create({
  tone: 'formal',
  monitor(m) {
    m.addEventListener('downloadprogress', (e) => {
      console.log(`Descargado ${e.loaded * 100}%`);
    });
  }
});
```
:::

::: {.split-col .demo-col}
<button id="btn-writer-create" class="demo-btn" onclick="runWriterCreation()">
  <span class="icon">‚öôÔ∏è</span> Crear Writer
</button>
<div class="progress-container">
  <div id="progress-writer-create" class="progress-bar"></div>
</div>
<div id="output-writer-create" class="demo-output">Esperando...</div>
:::

::: {.notes}
Pueden configurar el tono (formal, casual) y la longitud.
:::

:::

## Paso 3: Escribir {class="bg-writer playground-slide"}

::: {.split-layout .code-heavy .vertical}

::: {.split-col .code-col}
```javascript
const stream = await writer.writeStreaming(inputText);
for await (const chunk of stream) {
  console.log(chunk);
}
```
:::

::: {.split-col .demo-col}
<textarea id="input-writer-exec" class="demo-input" style="height: 80px;" placeholder="Escribe tu prompt aqu√≠...">Un correo para pedir vacaciones.</textarea>
<button id="btn-writer-exec" class="demo-btn" onclick="runWriterExecution()">
  <span class="icon">‚úçÔ∏è</span> Escribir
</button>
<div id="output-writer-exec" class="demo-output">El resultado aparecer√° aqu√≠...</div>
:::

::: {.notes}
Generaci√≥n de contenido basada en el prompt del usuario.
:::

:::

## Demo: Writer Playground

<iframe src="../writer-rewriter-api-playground/index.html" width="100%" height="600px" style="border: 1px solid #555; background: white;" data-preload></iframe>

## Casos de Uso: Rewriter

- Eliminar redundancias (ajuste de longitud).
- Ajustar tono y formalidad.
- Reformular lenguaje t√≥xico.
- Simplificar lenguaje complejo.

## Paso 1: Disponibilidad (Rewriter) {class="bg-rewriter"}

::: {.split-layout .code-heavy .vertical}

::: {.split-col .code-col}
```javascript
// Modern API: Rewriter
const availability = await Rewriter.availability();

if (availability === 'unavailable') {
  console.log("Modelo no disponible");
  return;
}

console.log("Modelo disponible:", availability);
```
:::

::: {.split-col .demo-col}
<button id="btn-rewriter-avail" class="demo-btn" onclick="runRewriterAvailability()">
  <span class="icon">‚ö°</span> Verificar Disponibilidad
</button>
<div id="output-rewriter-avail" class="demo-output">Esperando...</div>
:::

::: {.notes}
Refinar textos existentes es un caso de uso enorme.
:::

:::

## Paso 2: Crear Rewriter {class="bg-rewriter"}

Diferencia: `self.Rewriter` vs `self.Writer`

::: {.split-layout .code-heavy .vertical}

::: {.split-col .code-col}
```javascript
// Modern API: Rewriter
const rewriter = await Rewriter.create({
  tone: 'more-formal',
  length: 'shorter',
  monitor(m) {
    m.addEventListener('downloadprogress', (e) => {
      console.log(`Descargado ${e.loaded * 100}%`);
    });
  }
});
```
:::

::: {.split-col .demo-col}
<button id="btn-rewriter-create" class="demo-btn" onclick="runRewriterCreation()">
  <span class="icon">‚öôÔ∏è</span> Crear Rewriter
</button>
<div class="progress-container">
  <div id="progress-rewriter-create" class="progress-bar"></div>
</div>
<div id="output-rewriter-create" class="demo-output">Esperando...</div>
:::

::: {.notes}
Similar al Writer, pero optimizado para tomar un texto de entrada y transformarlo.
:::

:::

## Paso 3: Reescribir {class="bg-rewriter playground-slide"}

::: {.split-layout .code-heavy .vertical}

::: {.split-col .code-col}
```javascript
const stream = await rewriter.rewriteStreaming(
  inputText, 
  { context: contextText }
);

for await (const chunk of stream) {
  console.log(chunk);
}
```
:::

::: {.split-col .demo-col}
<textarea id="input-rewriter-exec" class="demo-input" style="height: 60px;" placeholder="Texto a reescribir...">Hola jefe, quiero vacaciones.</textarea>
<input type="text" id="context-rewriter-exec" class="demo-input" value="Correo formal" placeholder="Contexto (ej. Correo formal)">
<button id="btn-rewriter-exec" class="demo-btn" onclick="runRewriterExecution()">
  <span class="icon">‚úçÔ∏è</span> Reescribir
</button>
<div id="output-rewriter-exec" class="demo-output">El resultado aparecer√° aqu√≠...</div>
:::

::: {.notes}
Transformaci√≥n de texto con contexto opcional.
:::

:::

# Descripci√≥n General BYOM {class="bg-byom"}

<ul style="background: rgba(0,0,0,0.6); padding: 40px; border-radius: 15px;">
  <li><strong>Uso:</strong> Soporte cross-browser, modelos espec√≠ficos.</li>
  <li><strong>Stack:</strong> WebGPU + WebAssembly.</li>
  <li><strong>Librer√≠a:</strong> Google MediaPipe.</li>
</ul>

::: {.notes}
Para control total, privacidad absoluta o modelos espec√≠ficos que no est√°n en Chrome.
:::

## MediaPipe LLM Inference API {class="bg-byom"}

Ejecuta LLMs completamente en el dispositivo.

- **Tareas:** Generaci√≥n de texto, recuperaci√≥n de informaci√≥n, res√∫menes.
- **Modelos:** Gemma 2B, Gemma-3n (Multimodal: Texto, Imagen, Audio).
- **Privacidad:** Todo sucede en el cliente.

::: {.notes}
La API de LLM Inference te permite ejecutar modelos de lenguaje grandes (LLM) completamente en el dispositivo. Compatible con Gemma-3n para entradas de imagen y audio.
:::

## Configuraci√≥n R√°pida {class="bg-byom"}

1. **Instalar:**
   ```bash
   npm install @mediapipe/tasks-genai
   ```
2. **Descargar Modelo:**
   - Gemma-3n E4B o E2B (versiones "-Web").
   - [Hugging Face Community](https://huggingface.co/google)

::: {.notes}
Usa modelos convertidos espec√≠ficamente para la Web (terminan en .litertlm o .bin seg√∫n la versi√≥n).
:::

## Inicializaci√≥n {class="bg-byom"}

```javascript
const genai = await FilesetResolver.forGenAiTasks(
    "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-genai@latest/wasm"
);

const llm = await LlmInference.createFromOptions(genai, {
    baseOptions: 
      { 
        modelAssetPath: '/assets/gemma-3n-E4B-it-int4-Web.litertlm' 
      },
    maxTokens: 1000,
    topK: 40,
    temperature: 0.8
});

const response = await llm.generateResponse(inputPrompt);
```

::: {.notes}
`FilesetResolver` se encarga de cargar los binarios de WebAssembly (WASM) necesarios. `LlmInference` es la clase principal. Noten que apuntamos a un modelo `.litertlm` o `.bin` que hemos alojado en nuestros assets. Los par√°metros como `temperature` y `topK` controlan la creatividad del modelo.
:::


## Multimodalidad (Gemma-3n) {class="bg-byom"}

Soporte para Im√°genes y Audio.

```javascript
const llm = await LlmInference.createFromOptions(genai, {
    // ...
    maxNumImages: 5,
    supportAudio: true,
});

const response = await llm.generateResponse([
  'Describe ',
  {imageSource: '/assets/test_image.png'},
  ' and transcribe ',
  {audioSource: '/assets/test_audio.wav'}
]);
```

::: {.notes}
Gemma-3n es multimodal nativo. Pueden pasarle texto, im√°genes y audio en el mismo prompt. Esto abre posibilidades incre√≠bles para accesibilidad, an√°lisis de video frame-a-frame, y asistentes de voz m√°s naturales.
:::


## Personalizaci√≥n con LoRA {class="bg-byom"}

Adaptaci√≥n eficiente de modelos (Low-Rank Adaptation).

- Entrena pesos peque√±os en tus datos.
- Carga din√°mica en tiempo de ejecuci√≥n.

```javascript
// Configuraci√≥n
loraRanks: [4, 8, 16]

// Carga y Uso
const loraModel = await llm.loadLoraModel(loraModelUrl);
llm.generateResponse(prompt, loraModel, callback);
```

::: {.notes}
LoRA (Low-Rank Adaptation) permite "afinar" el modelo para tareas espec√≠ficas sin re-entrenarlo todo. Los pesos son peque√±os (pocos MBs) y se pueden cargar din√°micamente. Imaginen tener un modelo base y cargar "plugins" de LoRA para diferentes estilos de escritura o conocimientos espec√≠ficos.
:::


## Cargando el Modelo (Worker) {class="bg-byom"}

::: {.split-layout .code-heavy .vertical}

::: {.split-col .code-col}
```javascript
// perf-worker-gemma/src/worker.js
import { LlmInference, FilesetResolver } from '@mediapipe/tasks-genai';

const genai = await FilesetResolver.forGenAiTasks(wasmPath);
const llm = await LlmInference.createFromModelPath(genai, modelUrl);
self.postMessage({ status: 'READY' });
```
:::

::: {.split-col .demo-col style="justify-content: center;"}
**Clave:** ¬°Haz esto en un Web Worker!

<p style="font-size: 0.8em; opacity: 0.8;">Evita bloquear el hilo principal durante la carga pesada del modelo.</p>
:::

::: {.notes}
Archivos grandes (2GB+). Bloquear√≠an el navegador si no se hacen en un Worker.
:::

:::

## Ejecutando Inferencia {class="bg-byom"}

::: {.split-layout .code-heavy .vertical}

::: {.split-col .code-col}
```javascript
const response = await llm.generateResponse(userPrompt);
self.postMessage({ text: response });
```
:::

::: {.split-col .demo-col style="justify-content: center;"}
`generateResponse` es s√≠ncrono y pesado.

<p style="font-size: 0.8em; opacity: 0.8;">Si se ejecuta en el hilo principal, la p√°gina se congelar√° por completo.</p>
:::

::: {.notes}
C√°lculo intensivo. De nuevo, Worker es obligatorio.
:::

:::

## La Regla de Oro {class="bg-byom"}

::: {.split-layout .vertical-center}

::: {.split-col style="flex: 1;"}
<h3>NUNCA ejecutes inferencia en el Hilo Principal.</h3>
<p>Congela la UI.</p>
<h3>SIEMPRE usa un Web Worker.</h3>
:::

::: {.split-col style="flex: 1; display: flex; justify-content: center; align-items: center;"}
![](assets/main_thread_vs_worker.png){width="100%" style="border-radius: 15px; box-shadow: 0 4px 15px rgba(0,0,0,0.5);"}
:::

:::

::: {.notes}
Si recuerdan una cosa de hoy: NUNCA ejecuten inferencia en el hilo principal.
:::

## Demo: Worker vs No-Worker

<iframe src="../perf-worker-gemma/src/index.html" width="100%" height="600px" style="border: 1px solid #555; background: white;" data-preload></iframe>

# Transformers.js {class="bg-advanced"}

<ul style="background: rgba(0,0,0,0.6); padding: 40px; border-radius: 15px;">
  <li><strong>Uso:</strong> Modelos de Hugging Face en el navegador.</li>
  <li><strong>Stack:</strong> ONNX Runtime Web (WebAssembly / WebGPU).</li>
  <li><strong>Librer√≠a:</strong> @huggingface/transformers.</li>
</ul>

::: {.notes}
Transformers.js permite ejecutar modelos de √∫ltima generaci√≥n de Hugging Face directamente en el navegador.
:::

## Conceptos B√°sicos {class="bg-advanced"}

Comienza creando una instancia de `pipeline()` y especificando la tarea.

```javascript
import { pipeline } from '@huggingface/transformers';

// Crear pipeline de an√°lisis de sentimientos
const classifier = await pipeline('sentiment-analysis');
```

::: {.notes}
Al ejecutar por primera vez, descargar√° y almacenar√° en cach√© el modelo predeterminado. Las llamadas subsiguientes ser√°n mucho m√°s r√°pidas.
:::

## Inferencia {class="bg-advanced"}

Usa el clasificador en tu texto objetivo:

```javascript
const result = await classifier('¬°Amo Transformers.js!');
// [{'label': 'POSITIVE', 'score': 0.9998}]
```

M√∫ltiples entradas:

```javascript
const result = await classifier([
  '¬°Amo Transformers.js!', 
  'Odio los bugs.'
]);
// [{'label': 'POSITIVE', ...}, {'label': 'NEGATIVE', ...}]
```

::: {.notes}
La API es muy similar a la de Python, lo que facilita la migraci√≥n.
:::

## Modelos Personalizados {class="bg-advanced"}

Puedes especificar un modelo diferente como segundo argumento.

```javascript
// Usar un modelo espec√≠fico (ej. estrellas 1-5)
const reviewer = await pipeline(
  'sentiment-analysis', 
  'Xenova/bert-base-multilingual-uncased-sentiment'
);

const result = await reviewer(
  'The Shawshank Redemption es una obra maestra.'
);
// [{label: '5 stars', score: 0.81...}]
```

::: {.notes}
Por defecto usa modelos cuantizados para la web, pero puedes elegir cualquiera compatible en el Hub.
:::

# Respuestas en Streaming (SSE) {class="bg-advanced"}

No esperes la respuesta completa.

Transmite tokens a medida que se generan.

<div style="font-size: 3em; margin-top: 20px;">üåä ‚û°Ô∏è üìÑ</div>

::: {.notes}
UX percibida es todo. El usuario siente que "piensa" r√°pido.
:::

## Ejemplo Streaming Node.js {class="bg-advanced"}

::: {.split-layout .code-heavy .vertical}

::: {.split-col .code-col}
```javascript
// gemini-node-sse/index.js
const result = await model.generateContentStream(prompt);
for await (const chunk of result.stream) {
    res.write(`data: ${JSON.stringify(chunk.text())}\n\n`);
}
```
:::

::: {.split-col .demo-col style="justify-content: center;"}
Server-Sent Events (SSE) permite enviar actualizaciones en tiempo real al cliente.
:::

::: {.notes}
El backend tambi√©n puede hacer streaming. Server-Sent Events es perfecto para esto.
:::

:::

## Gestionando Contexto

<ul style="background: rgba(0,0,0,0.3); padding: 30px; border-radius: 15px; list-style: none;">
  <li>üß† <strong>RAM Limitada:</strong> 4k-8k tokens en m√≥viles.</li>
  <li>‚úÇÔ∏è <strong>Truncado:</strong> Corta el historial agresivamente.</li>
  <li>üéØ <strong>System Prompts:</strong> √ösalos para definir comportamiento eficientemente.</li>
</ul>

::: {.notes}
Ventana de contexto limitada en m√≥viles. Sean inteligentes con lo que env√≠an.
:::

## Prompting One-Shot {class="bg-advanced"}

¬°Dale un ejemplo al modelo!

::: {.comparison-box}

::: {.comparison-item .bad}
**‚ùå Mal:** "Clasifica esta rese√±a."
:::

::: {.comparison-item .good}
**‚úÖ Bien:** "Clasifica como Positiva/Negativa. <br>Ejemplo: '¬°Me encanta!' -> Positiva.
<br>Ahora clasifica: 'Lo odi√©.'"
:::

::: {.notes}
Ejemplos ayudan mucho al modelo a entender el formato y tono deseado.
:::

:::

## {background-image="assets/arquitectura_hibrida.jpeg" background-size="contain"}

::: {.notes}
Lo mejor de dos mundos. R√°pido y privado para lo simple. Potente y capaz para lo complejo.
:::

## Demo del Mundo Real {class="bg-advanced"}

#### Rese√±as de Productos

::: {style="background: rgba(0,0,0,0.3); padding: 30px; border-radius: 15px;"}
1. üë§ Usuario escribe rese√±a.
2. üõ°Ô∏è **Local:** Verificar toxicidad (Transformers.js).
3. ‚ú® **Local:** Sugerir mejoras (Gemma).
:::

::: {.notes}
Un flujo completo: Local para inmediatez, Nube para potencia si es necesario.
:::

## Demo: Product Reviews

<iframe src="../product-review-suggestions/src/index.html" width="100%" height="600px" style="border: 1px solid #555; background: white;" data-preload></iframe>


## Soporte del Navegador {class="bg-advanced"}

<div style="display: flex; gap: 40px; justify-content: center; align-items: stretch; margin-top: 50px;">
<div style="flex: 1; background: rgba(255, 255, 255, 0.05); padding: 40px; border-radius: 20px; border: 1px solid rgba(255, 255, 255, 0.1); backdrop-filter: blur(10px); display: flex; flex-direction: column; align-items: center; text-align: center; box-shadow: 0 8px 32px 0 rgba(0, 0, 0, 0.3);">
<div style="font-size: 3em; margin-bottom: 20px;">ü§ñ</div>
<h3 style="margin-top: 0; color: #a8dadc;">Built-in AI</h3>
<p style="font-size: 1.2em; margin: 10px 0;">Chrome Desktop</p>
<div style="background: rgba(255, 215, 0, 0.2); color: #ffd700; padding: 5px 15px; border-radius: 20px; font-size: 0.8em; font-weight: bold; display: inline-block;">Canary / Dev</div>
</div>
<div style="flex: 1; background: rgba(255, 255, 255, 0.05); padding: 40px; border-radius: 20px; border: 1px solid rgba(255, 255, 255, 0.1); backdrop-filter: blur(10px); display: flex; flex-direction: column; align-items: center; text-align: center; box-shadow: 0 8px 32px 0 rgba(0, 0, 0, 0.3);">
<div style="font-size: 3em; margin-bottom: 20px;">‚ö°</div>
<h3 style="margin-top: 0; color: #a8dadc;">BYOM (WebGPU)</h3>
<p style="font-size: 1.2em; margin: 10px 0;">Chrome, Edge, Firefox</p>
<div style="background: rgba(0, 255, 127, 0.2); color: #00ff7f; padding: 5px 15px; border-radius: 20px; font-size: 0.8em; font-weight: bold; display: inline-block;">Broad Support</div>
</div>
</div>

::: {.notes}
El soporte est√° creciendo. Chrome lidera con Built-in AI, pero WebGPU (la base de BYOM) ya est√° en todos los navegadores modernos.
:::

## Recursos {class="bg-advanced"}

::: {style="font-size: 0.8em;"}
- üì¶ `github.com/GoogleChromeLabs/web-ai-demos`
- üìö `developer.chrome.com/docs/ai`
- ü§ñ `ai.google.dev/edge/mediapipe`
:::

::: {.notes}
Aqu√≠ tienen los enlaces al repo con todos estos demos y la documentaci√≥n oficial.
:::

## {background-gradient="linear-gradient(to bottom right, #ff9966, #ff5e62)"}

<img src="assets/WebGDE Avatar.png" style="width: 150px; height: 150px; border-radius: 50%; border: 4px solid white; box-shadow: 0 4px 10px rgba(0,0,0,0.3); margin-bottom: 20px;">
<p style="font-size: 1.5em;">@sebasgojs</p>
<p style="font-size: 1.5em;">sebastian-gomez.com</p>
<p style="font-size: 1.5em;">youtube.com/@sebasgojs</p>
<p style="margin-top: 50px;"><small>Ve y construye algo m√°gico. ‚ú®</small></p>

::: {.notes}
¬°Gracias por su tiempo! Estoy abierto a preguntas. ¬°Vayan y construyan algo incre√≠ble con Web AI!
:::
